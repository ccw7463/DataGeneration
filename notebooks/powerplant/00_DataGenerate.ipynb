{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/changwoo/DataGeneration/models/model.py:7: LangChainDeprecationWarning: The class `HuggingFaceEndpoint` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEndpoint``.\n",
      "  llm=HuggingFaceEndpoint(\n",
      "/root/.cache/pypoetry/virtualenvs/datageneration-Lyt16Uhg-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/workspace/changwoo/DataGeneration/models/model.py:6: LangChainDeprecationWarning: The class `ChatHuggingFace` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import ChatHuggingFace``.\n",
      "  LLM = ChatHuggingFace(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "import chardet\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import json\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "from models.model import LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib.resources import files\n",
    "DATA_PATH = files(\"data\")\n",
    "RAW_PATH = str(DATA_PATH.joinpath(\"raw/*.csv\"))\n",
    "PREPROCESSED_PATH = str(DATA_PATH.joinpath(\"preprocessed/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA = sorted(glob(RAW_PATH))\n",
    "\n",
    "def extract_df(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        result = chardet.detect(f.read())\n",
    "    name, df = os.path.basename(path), pd.read_csv(path, encoding=result['encoding'])\n",
    "    return name, df\n",
    "\n",
    "dfs = [extract_df(i) for i in RAW_DATA]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  9.65it/s]\n"
     ]
    }
   ],
   "source": [
    "queries = []\n",
    "for name, df in tqdm(dfs):\n",
    "    cols = list(df.columns)\n",
    "    for _, rows in df.iterrows():\n",
    "        text = \"\"\n",
    "        for row, col in zip(rows, cols):\n",
    "            text += col + \" : \" + str(row) + \"\\n\"\n",
    "        queries.append([name, text])\n",
    "        text = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new graph\n",
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "# Define Call model\n",
    "def call_model(state: MessagesState):\n",
    "    response = LLM.invoke(state[\"messages\"])\n",
    "    return {\"messages\": response}\n",
    "\n",
    "# Set Node\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "# Set Edge\n",
    "workflow.add_edge(START, \"model\")\n",
    "\n",
    "# Set Memory \n",
    "memory = MemorySaver()\n",
    "# graph = workflow.compile(checkpointer=memory)\n",
    "graph = workflow.compile()\n",
    "\n",
    "# Set Config\n",
    "config = {\"configurable\": {\"thread_id\": \"abc124\"}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1-1) Prompt for Instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "BASE_PROMPT = \"\"\"\n",
    "발전소 관련 데이터를 생성하고 있습니다.\n",
    "용어에 대한 정의를 나타내는 문장을 생성하세요.\n",
    "\n",
    "예를 들어, 아래와 같은 형식으로 주요 용어를 정의할 수 있습니다:\n",
    "발전소(Power Plant)는 전기를 생산하기 위해 다양한 에너지원(화석 연료, 원자력, 재생 가능 에너지 등)을 이용하여 전력을 생성하고 이를 전력망에 공급하는 시설을 말한다. 발전소는 사용하는 에너지원과 발전 방식에 따라 여러 종류로 구분된다.\n",
    "\n",
    "다음 지시사항을 따르세요.\n",
    "1. 한국어와 영어를 제외한 언어는 사용하지 않습니다.\n",
    "2. 정확히 아는 정보에 대해서는 자세히 설명합니다.\n",
    "3. 생성해야할 용어에 대한 정보는 [용어 정보]를 참고하세요.\n",
    "\n",
    "[용어 정보]\n",
    "{query}\n",
    "\n",
    "생성 문장 :\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1-2) Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7108/7108 [7:10:27<00:00,  3.63s/it]   \n"
     ]
    }
   ],
   "source": [
    "SAVE_PATH = os.path.join(PREPROCESSED_PATH,'PowerPlant_Glossary.json')\n",
    "\n",
    "try:\n",
    "    dataset = json.load(open(SAVE_PATH, 'r', encoding='utf-8'))\n",
    "except:\n",
    "    dataset = []\n",
    "\n",
    "for idx, query in enumerate(tqdm(queries)):\n",
    "    PROMPT = BASE_PROMPT.format(query=query[1])\n",
    "    INPUT_MESSAGES = [SystemMessage(content=\"당신은 데이터 생성 어시스턴트입니다.\"), \n",
    "                      HumanMessage(PROMPT)]\n",
    "    try:\n",
    "        output = graph.invoke({\"messages\":INPUT_MESSAGES}, config)[\"messages\"][-1].content\n",
    "        dataset.append({\"name\": query[0],\n",
    "                        \"info\": query[1],\n",
    "                        \"prompt\": PROMPT,\n",
    "                        \"response\": output})\n",
    "        with open(SAVE_PATH, 'w', encoding='utf-8') as file:\n",
    "            json.dump(dataset, file, ensure_ascii=False, indent=4)\n",
    "    except Exception as e:\n",
    "        with open(f'error_log.txt', 'a', encoding='utf-8') as file:\n",
    "            file.write(f\"{idx} : {query[1]} : {e}\\n\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2-1) Prompt for Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "BASE_PROMPT = \"\"\"\n",
    "발전소 관련 데이터를 생성하고 있습니다.\n",
    "다음 답변에 대한 요청문을 생성하세요.\n",
    "\n",
    "예를 들어 주어진 정보가 있을때, 생성된 요청문은 아래와 같습니다.\n",
    "\n",
    "# 주어진 정보\n",
    "태양광발전 판넬(Photovoltaic Panel)은 태양광을 전기 에너지로 변환하는 태양전지 모듈들을 기계적으로 결합하여 널판 형태로 만든 집합체를 말한다. 이 판넬은 어레이 또는 하위의 소어레이에 설치 가능한 단위로 설계되어 미리 조립하고 결선하여 함께 결합된 형태로 제공되며, 현장에서 쉽게 조립할 수 있도록 설계되어 있다.\n",
    "\n",
    "# 생성된 요청문\n",
    "태양광발전시스템에 대해 설명해주세요.\n",
    "\n",
    "다음 지시사항을 따르세요.\n",
    "1. 한국어와 영어를 제외한 언어는 사용하지 않습니다.\n",
    "2. 요청문은 간결한 문장 1개만 사용하세요.\n",
    "3. 요청문은 용어에 대한 정의를 묻는 질문만 사용합니다.\n",
    "4. 요청문은 다양한 형태를 사용할 수 있습니다. 예를들어, 아래중에 한가지를 사용할 수 있습니다.\n",
    "    4.1 태양광발전시스템에 대해 설명해주세요.\n",
    "    4.2 태양광발전시스템이 뭐죠?\n",
    "    4.3 태양광발전시스템에 대해 알려주실래요?\n",
    "    4.4 태양광발전시스템이 뭔가요?\n",
    "    4.5 태양광발전시스템에 대해 알려주세요.\n",
    "\n",
    "[주어진 정보]\n",
    "{response}\n",
    "\n",
    "생성된 요청문 :\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2-2) Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15444/15444 [2:25:47<00:00,  1.77it/s]  \n"
     ]
    }
   ],
   "source": [
    "PREVIOUS_SAVE_PATH = os.path.join(PREPROCESSED_PATH,'PowerPlant_Glossary.json')\n",
    "NEW_SAVE_PATH = os.path.join(PREPROCESSED_PATH,'PowerPlant_Glossary_ver2.json')\n",
    "dataset = json.load(open(PREVIOUS_SAVE_PATH, 'r', encoding='utf-8'))\n",
    "\n",
    "try:\n",
    "    new_dataset = json.load(open(NEW_SAVE_PATH, 'r', encoding='utf-8'))\n",
    "except:\n",
    "    new_dataset = []\n",
    "\n",
    "for idx, query in enumerate(tqdm(dataset)):\n",
    "    PROMPT = BASE_PROMPT.format(response=query['response'])\n",
    "    INPUT_MESSAGES = [SystemMessage(content=\"당신은 데이터 생성 어시스턴트입니다.\"), \n",
    "                      HumanMessage(PROMPT)]\n",
    "    try:\n",
    "        output = graph.invoke({\"messages\":INPUT_MESSAGES}, config)[\"messages\"][-1].content\n",
    "        new_dataset.append({\"name\": query['name'],\n",
    "                            \"info\": query['info'],\n",
    "                            \"prompt_for_instruction\": PROMPT,\n",
    "                            \"prompt_for_response\": query['prompt'],\n",
    "                            \"instruction\": output,\n",
    "                            \"response\": query['response']})\n",
    "        with open(NEW_SAVE_PATH, 'w', encoding='utf-8') as file:\n",
    "            json.dump(new_dataset, file, ensure_ascii=False, indent=4)\n",
    "    except Exception as e:\n",
    "        with open(f'error_log.txt', 'a', encoding='utf-8') as file:\n",
    "            file.write(f\"{idx} : {query[1]} : {e}\\n\")\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_poetry_env",
   "language": "python",
   "name": "my_poetry_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
