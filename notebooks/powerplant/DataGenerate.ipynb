{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "import chardet\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import json\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "from models.model import LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA = sorted(glob('data/raw/*.csv'))\n",
    "\n",
    "def extract_df(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        result = chardet.detect(f.read())\n",
    "    name, df = os.path.basename(path), pd.read_csv(path, encoding=result['encoding'])\n",
    "    return name, df\n",
    "\n",
    "dfs = [extract_df(i) for i in RAW_DATA]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  9.53it/s]\n"
     ]
    }
   ],
   "source": [
    "queries = []\n",
    "for name, df in tqdm(dfs):\n",
    "    cols = list(df.columns)\n",
    "    for _, rows in df.iterrows():\n",
    "        text = \"\"\n",
    "        for row, col in zip(rows, cols):\n",
    "            text += col + \" : \" + str(row) + \"\\n\"\n",
    "        queries.append([name, text])\n",
    "        text = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangGraph 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new graph\n",
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "# Define Call model\n",
    "def call_model(state: MessagesState):\n",
    "    response = LLM.invoke(state[\"messages\"])\n",
    "    return {\"messages\": response}\n",
    "\n",
    "# Set Node\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "# Set Edge\n",
    "workflow.add_edge(START, \"model\")\n",
    "\n",
    "# Set Memory \n",
    "memory = MemorySaver()\n",
    "# graph = workflow.compile(checkpointer=memory)\n",
    "graph = workflow.compile()\n",
    "\n",
    "# Set Config\n",
    "config = {\"configurable\": {\"thread_id\": \"abc124\"}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "프롬프트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "BASE_PROMPT = \"\"\"\n",
    "발전소 관련 데이터를 생성하고 있습니다.\n",
    "용어에 대한 정의를 나타내는 문장을 생성하세요.\n",
    "\n",
    "예를 들어, 아래와 같은 형식으로 주요 용어를 정의할 수 있습니다:\n",
    "발전소(Power Plant)는 전기를 생산하기 위해 다양한 에너지원(화석 연료, 원자력, 재생 가능 에너지 등)을 이용하여 전력을 생성하고 이를 전력망에 공급하는 시설을 말한다. 발전소는 사용하는 에너지원과 발전 방식에 따라 여러 종류로 구분된다.\n",
    "\n",
    "다음 지시사항을 따르세요.\n",
    "1. 한국어와 영어를 제외한 언어는 사용하지 않습니다.\n",
    "2. 정확히 아는 정보에 대해서는 자세히 설명합니다.\n",
    "3. 생성해야할 용어에 대한 정보는 [용어 정보]를 참고하세요.\n",
    "\n",
    "[용어 정보]\n",
    "{query}\n",
    "\n",
    "생성 문장 :\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 생성 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7108/7108 [7:10:27<00:00,  3.63s/it]   \n"
     ]
    }
   ],
   "source": [
    "SAVE_PATH = 'data/preprocessed/PowerPlant_Glossary.json'\n",
    "\n",
    "try:\n",
    "    dataset = json.load(open(SAVE_PATH, 'r', encoding='utf-8'))\n",
    "except:\n",
    "    dataset = []\n",
    "\n",
    "for idx, query in enumerate(tqdm(queries[1892:9000])):\n",
    "    PROMPT = BASE_PROMPT.format(query=query[1])\n",
    "    INPUT_MESSAGES = [SystemMessage(content=\"당신은 데이터 생성 어시스턴트입니다.\"), \n",
    "                      HumanMessage(PROMPT)]\n",
    "    try:\n",
    "        output = graph.invoke({\"messages\":INPUT_MESSAGES}, config)[\"messages\"][-1].content\n",
    "        dataset.append({\"name\": query[0],\n",
    "                        \"info\": query[1],\n",
    "                        \"prompt\": PROMPT,\n",
    "                        \"response\": output})\n",
    "        with open(SAVE_PATH, 'w', encoding='utf-8') as file:\n",
    "            json.dump(dataset, file, ensure_ascii=False, indent=4)\n",
    "    except Exception as e:\n",
    "        with open(f'error_log.txt', 'a', encoding='utf-8') as file:\n",
    "            file.write(f\"{idx} : {query[1]} : {e}\\n\")\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_poetry_env",
   "language": "python",
   "name": "my_poetry_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
