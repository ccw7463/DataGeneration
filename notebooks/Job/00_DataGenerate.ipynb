{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Job Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import chardet\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from module.rss import RSSGetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "class DataGenerator:\n",
    "    def __init__(self):\n",
    "        self.openai_api_key = \"EMPTY\"\n",
    "        self.openai_api_base = \"http://192.168.1.20:1318/v1\"\n",
    "        self.client = OpenAI(\n",
    "            api_key=self.openai_api_key,\n",
    "            base_url=self.openai_api_base,\n",
    "        )\n",
    "        self.USE_MODEL = \"pixtral\"\n",
    "        self.MODEL_NAME_DICT = {\n",
    "            \"qwen\": \"Qwen/Qwen2-VL-72B-Instruct\",\n",
    "            \"pixtral\": \"mistralai/Pixtral-Large-Instruct-2411\"\n",
    "        }\n",
    "        self.MODEL_NAME = self.MODEL_NAME_DICT[self.USE_MODEL]\n",
    "        self.SYSTEM_PROMPT_DICT = {\n",
    "            \"qwen\": \"You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\",\n",
    "            \"pixtral\": \"You are a helpful assistant.\"\n",
    "        }\n",
    "        self.SYSTEM_PROMPT = self.SYSTEM_PROMPT_DICT[self.USE_MODEL]\n",
    "\n",
    "    def LLM_Call(self, \n",
    "                 prompt: str) -> str:\n",
    "        chat_response = self.client.chat.completions.create(\n",
    "            model=self.MODEL_NAME,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": self.SYSTEM_PROMPT},\n",
    "                {\"role\": \"user\", \"content\": f\"{prompt}\"},\n",
    "            ],\n",
    "            temperature=0.001,\n",
    "            top_p=0.001,\n",
    "            max_tokens=4096,\n",
    "            extra_body={\n",
    "                \"repetition_penalty\": 1.03,\n",
    "            },\n",
    "        )\n",
    "        return chat_response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_question(job_name: str,\n",
    "                 question_type: str) -> str:\n",
    "    prompt = f\"\"\"ë‹¹ì‹ ì€ ë°ì´í„° ìƒì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "    \n",
    "    [ì§ì—… ì´ë¦„]ê³¼ [ì§ˆë¬¸ ì¢…ë¥˜]ë¥¼ ì°¸ê³ í•˜ì—¬, ì§ˆë¬¸ ë˜ëŠ” ìš”ì²­ë¬¸ì„ 1ê°œ ìƒì„±í•´ì£¼ì„¸ìš”.\n",
    "    ë¬´ì¡°ê±´ ì§ˆë¬¸ ë˜ëŠ” ìš”ì²­ë¬¸ë§Œ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    ì§ˆë¬¸ ë˜ëŠ” ìš”ì²­ë¬¸ì€ ë¬´ì¡°ê±´ í•œêµ­ì–´ë¡œ ìƒì„±í•©ë‹ˆë‹¤. \n",
    "    \n",
    "    ì˜ˆë¥¼ë“¤ì–´,\n",
    "    1. **ê°€ í•˜ëŠ”ì¼ì€ ë¬´ì—‡ì¸ê°€ìš”?\n",
    "    2. **ì˜ ì§ë¬´ì— ëŒ€í•´ì„œ ì•Œë ¤ì£¼ì„¸ìš”.\n",
    "    3. **ì˜ ì—°ë´‰ì€ ì–¼ë§ˆì¯¤ì¸ê°€ìš”?\n",
    "    4. **ì˜ ì „ë§ì€ ì–´ë–¤ê°€ìš”?\n",
    "    5. **ì˜ ì„ê¸ˆ ìƒìŠ¹ë¥ ì€ ì–´ë–¤ê°€ìš”?\n",
    "    6. **ê°€ í•˜ëŠ”ì¼ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”.\n",
    "    7. **ì˜ ì—°ë´‰ì— ëŒ€í•´ ì•Œë ¤ì£¼ì‹¤ë˜ìš”?\n",
    "    8. **ì˜ ì „ë§ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”.\n",
    "    \n",
    "    [ì§ì—… ì´ë¦„]\n",
    "    {job_name}\n",
    "    \n",
    "    [ì§ˆë¬¸ ì¢…ë¥˜]\n",
    "    {question_type}\n",
    "    \"\"\"\n",
    "    return prompt\n",
    "\n",
    "def get_answer(job_name: str,\n",
    "               question: str) -> str:\n",
    "    prompt = f\"\"\"ë‹¹ì‹ ì€ ë°ì´í„° ìƒì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "    \n",
    "    [ì§ì—… ì´ë¦„]ê³¼ [ì§ˆë¬¸]ì„ ì°¸ê³ í•˜ì—¬, ë‹µë³€ì„ ìƒì„±í•´ì£¼ì„¸ìš”.\n",
    "    ë‹µë³€ì€ ë¬´ì¡°ê±´ í•œêµ­ì–´ë¡œ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    [ì§ì—… ì´ë¦„]\n",
    "    {job_name}\n",
    "    \n",
    "    [ì§ˆë¬¸]\n",
    "    {question}\n",
    "    \"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ–¥ChromeDriverê°€ ì¡´ì¬í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "job_data_generator = DataGenerator()\n",
    "rss = RSSGetter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë°ì´í„° ì¢…ë¥˜\n",
    "- 1. ì§ë¬´, í•˜ëŠ”ì¼ (Job Description, Job Duties)\n",
    "- 2. ì„ê¸ˆ, ì—°ë´‰ (Salary, Annual Salary)\n",
    "- 3. ì „ë§ (Job Outlook, Job Growth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = chardet.detect(open('job_data.csv', 'rb').read())\n",
    "df = pd.read_csv('job_data.csv',\n",
    "                 encoding=encoding['encoding'])\n",
    "job_list = list(df['KNOWì§ì—…ëª…'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JSON_DATA = []\n",
    "for job in tqdm(job_list):\n",
    "    print(f\"ì§ì—…ì´ë¦„ : {job}\")\n",
    "    try:\n",
    "        for question_type in [\"ì§ë¬´, í•˜ëŠ”ì¼\", \"ì„ê¸ˆ, ì—°ë´‰\", \"ì „ë§\"]:\n",
    "            question_prompt = get_question(job, question_type).strip()\n",
    "            question = job_data_generator.LLM_Call(question_prompt).strip()\n",
    "            answer_prompt = get_answer(job, question).strip()\n",
    "            answer = job_data_generator.LLM_Call(answer_prompt).strip()\n",
    "            JSON_DATA.append({\n",
    "                \"job_name\": job,\n",
    "                \"question_type\": question_type,\n",
    "                \"question_prompt\": question_prompt,\n",
    "                \"question\": question,\n",
    "                \"answer_prompt\": answer_prompt,\n",
    "                \"answer\": answer\n",
    "            })\n",
    "    except:\n",
    "        print(f\"Error: {job}\")\n",
    "        continue\n",
    "    with open(\"job_data.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(JSON_DATA, f, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
