{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "openai_api_key = \"EMPTY\"\n",
    "openai_api_base = \"http://192.168.1.20:1318/v1\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=openai_api_key,\n",
    "    base_url=openai_api_base,\n",
    ")\n",
    "\n",
    "USE_MODEL = \"pixtral\"\n",
    "MODEL_NAME_DICT = {\"qwen\": \"Qwen/Qwen2-VL-72B-Instruct\",\n",
    "                   \"pixtral\": \"mistralai/Pixtral-Large-Instruct-2411\"}\n",
    "MODEL_NAME = MODEL_NAME_DICT[USE_MODEL]\n",
    "SYSTEM_PROMPT_DICT = {\"qwen\": \"You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\",\n",
    "                      \"pixtral\": \"You are a helpful assistant.\"} # TODO : pixtral 프롬프트 지정 필요\n",
    "SYSTEM_PROMPT = SYSTEM_PROMPT_DICT[USE_MODEL]\n",
    "def LLM_Call(prompt:str):\n",
    "    chat_response = client.chat.completions.create(\n",
    "        model=MODEL_NAME,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": f\"{prompt}\"},\n",
    "        ],\n",
    "        temperature=0.001,\n",
    "        top_p=0.001,\n",
    "        max_tokens=4096,\n",
    "        extra_body={\n",
    "            \"repetition_penalty\": 1.03,\n",
    "        },\n",
    "    )\n",
    "    return chat_response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import ast\n",
    "\n",
    "def extract_data_dict(result):\n",
    "    pattern = re.compile(r\"(?<=python\\n)\\{[\\s\\S]*?\\}\")\n",
    "    match = pattern.search(result)\n",
    "    if match:\n",
    "        data_str = match.group(0)\n",
    "        data_dict = ast.literal_eval(data_str)\n",
    "        return data_dict\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def get_attack_type_samples(df:pd.DataFrame,\n",
    "                          attack_type:str,\n",
    "                          num_samples:int=25):\n",
    "    ATTACK_TYPE_SAMPLES = df[df['Attack type']==attack_type].sample(num_samples)\n",
    "    ATTACK_TYPE_SAMPLES.columns = ATTACK_TYPE_SAMPLES.columns.str.strip()\n",
    "    ATTACK_TYPE_SAMPLES.reset_index(drop=True, inplace=True)\n",
    "    ATTACK_TYPE_SAMPLES.drop(columns=[\"Attack type\"], inplace=True)\n",
    "    attack_type_md = ATTACK_TYPE_SAMPLES.to_markdown()\n",
    "    return attack_type_md\n",
    "\n",
    "desc_dict = {\n",
    "    \"id\": \"A unique ID to distinguish the sensor node in any round and at any stage. For example, node number 25 in the third round and in the first stage is to be symbolized as 001 003 025.\",\n",
    "    \"Time\": \"The current simulation time of the node.\",\n",
    "    \"Is_CH\": \"A flag to distinguish whether the node is CH with value 1 or normal node with value 0.\",\n",
    "    \"who CH\": \"The ID of the CH in the current round.\",\n",
    "    \"Dist_To_CH\": \"The distance between the node and its CH in the current round.\",\n",
    "    \"ADV_S\": \"The number of advertise CH’s broadcast messages sent to the nodes.\",\n",
    "    \"ADV_R\": \"The number of advertise CH messages received from CHs.\",\n",
    "    \"JOIN_S\": \"The number of join request messages sent by the nodes to the CH.\",\n",
    "    \"JOIN_R\": \"The number of join request messages received by the CH from the nodes.\",\n",
    "    \"SCH_S\": \"The number of advertise TDMA schedule broadcast messages sent to the nodes.\",\n",
    "    \"SCH_R\": \"The number of TDMA schedule messages received from CHs.\",\n",
    "    \"Rank\": \"The order of this node within the TDMA schedule.\",\n",
    "    \"DATA_S\": \"The number of data packets sent from a sensor to its CH.\",\n",
    "    \"DATA_R\": \"The number of data packets received from CH.\",\n",
    "    \"Data_Sent_To_BS\": \"The number of data packets sent to the BS.\",\n",
    "    \"dist_CH_To_BS\": \"The distance between the CH and the BS.\",\n",
    "    \"send_code\": \"The cluster sending code.\",\n",
    "    \"Expaned Energy\": \"The amount of energy consumed in the previous round.\",\n",
    "}\n",
    "description_md = \"| Key           | Description |\\n\"\n",
    "description_md += \"|-------------------|-----------------|\\n\"\n",
    "for key, description in desc_dict.items():\n",
    "    description_md += f\"| {key} | {description} |\\n\"\n",
    "    \n",
    "returns_format = \"\"\"```python\n",
    "{\n",
    "    'id': value,\n",
    "    'Time': value,\n",
    "    'Is_CH': value,\n",
    "    'who CH': value,\n",
    "    'Dist_To_CH': value,\n",
    "    'ADV_S': value,\n",
    "    'ADV_R': value,\n",
    "    'JOIN_S': value,\n",
    "    'JOIN_R': value,\n",
    "    'SCH_S': value,\n",
    "    'SCH_R': value,\n",
    "    'Rank': value,\n",
    "    'DATA_S': value,\n",
    "    'DATA_R': value,\n",
    "    'Data_Sent_To_BS': value,\n",
    "    'dist_CH_To_BS': value,\n",
    "    'send_code': value,\n",
    "    'Expaned Energy': value\n",
    "}\n",
    "```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PROMPT = \"\"\"\n",
    "당신은 데이터 생성 전문가이다.\n",
    "\n",
    "WSN-DS (Wireless Sensor Network Detection System) 데이터셋에서\n",
    "Blackhole 공격 유형에 대해 데이터를 생성하고자 한다.\n",
    "\n",
    "아래 [Description]과 [Examples]를 참고하여 데이터를 한개 생성하라. \n",
    "\n",
    "[Description]\n",
    "{description_md}\n",
    "\n",
    "[Examples]\n",
    "{attack_type_md}\n",
    "\n",
    "데이터는 딕셔너리 형태로, examples 예시와 동일한 key, value 형태를 참고해서 아래 [Returns] 형태로 생성하라. \n",
    "\n",
    "[Returns]\n",
    "{returns_format}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATTACK_TYPES = ['Grayhole', 'Blackhole', 'TDMA', 'Flooding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsn_df = pd.read_csv(\"WSN-DS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_attack_type_samples = []\n",
    "# for attack_type in ATTACK_TYPES:\n",
    "#     for i in tqdm(range(150)):\n",
    "#         PROMPT = BASE_PROMPT.format(description_md=description_md, \n",
    "#                                     attack_type_md=get_attack_type_samples(df=wsn_df, \n",
    "#                                                                            attack_type=attack_type, \n",
    "#                                                                            num_samples=25), \n",
    "#                                     returns_format=returns_format)\n",
    "#         result = LLM_Call(PROMPT)\n",
    "#         data_dict = extract_data_dict(result)\n",
    "#         if data_dict is not None:\n",
    "#             data_dict['Attack type'] = attack_type\n",
    "#             new_attack_type_samples.append(data_dict)\n",
    "#         else:\n",
    "#             print(f\"Failed to extract data_dict from result {i}\")\n",
    "# new_attack_type_samples = pd.DataFrame(new_attack_type_samples)\n",
    "# new_attack_type_samples.to_csv(\"new_attack_type_samples_ver2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_df = wsn_df[wsn_df['Attack type']==\"Normal\"].sample(400,random_state=42)\n",
    "normal_df.columns = normal_df.columns.str.strip()\n",
    "concat_original_df = copy.deepcopy(normal_df)\n",
    "for attack_type in ATTACK_TYPES:\n",
    "    attack_type_df = wsn_df[wsn_df['Attack type']==attack_type].sample(200,random_state=42)\n",
    "    attack_type_df.columns = attack_type_df.columns.str.strip()\n",
    "    concat_original_df = pd.concat([concat_original_df, attack_type_df], ignore_index=True)\n",
    "    \n",
    "new_attack_type_df = pd.read_csv(f\"augmented_with_LLM.csv\")\n",
    "new_attack_type_df.columns = new_attack_type_df.columns.str.strip()\n",
    "concat_all_df = pd.concat([concat_original_df,new_attack_type_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LLM-based Augmentation Result]\n",
      "Accuracy: 0.9075\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Blackhole       0.75      0.96      0.84        85\n",
      "    Flooding       1.00      0.99      0.99        75\n",
      "    Grayhole       0.95      0.67      0.79        85\n",
      "      Normal       0.95      0.99      0.97        83\n",
      "        TDMA       0.97      0.94      0.96        72\n",
      "\n",
      "    accuracy                           0.91       400\n",
      "   macro avg       0.92      0.91      0.91       400\n",
      "weighted avg       0.92      0.91      0.91       400\n",
      "\n",
      "[SMOTE-based Augmentation Result]\n",
      "Accuracy: 0.91\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Blackhole       0.71      0.97      0.82        69\n",
      "    Flooding       1.00      1.00      1.00        78\n",
      "    Grayhole       0.99      0.71      0.83        94\n",
      "      Normal       0.94      0.98      0.96        83\n",
      "        TDMA       0.96      0.93      0.95        76\n",
      "\n",
      "    accuracy                           0.91       400\n",
      "   macro avg       0.92      0.92      0.91       400\n",
      "weighted avg       0.93      0.91      0.91       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_sample_based_LLM = concat_all_df.drop(columns=[\"Attack type\"])\n",
    "Y_sample_based_LLM = concat_all_df[\"Attack type\"]\n",
    "# print(X_sample_based_LLM.shape, Y_sample_based_LLM.shape)\n",
    "X_train_based_LLM, X_test_based_LLM, y_train_based_LLM, y_test_based_LLM = train_test_split(X_sample_based_LLM, Y_sample_based_LLM, test_size=0.2, random_state=42)\n",
    "scaler_resampling = StandardScaler()\n",
    "X_train_scaled = scaler_resampling.fit_transform(X_train_based_LLM)\n",
    "X_test_scaled = scaler_resampling.transform(X_test_based_LLM)\n",
    "logreg_resampling = LogisticRegression(max_iter=1000, random_state=42)\n",
    "logreg_resampling.fit(X_train_scaled, y_train_based_LLM)\n",
    "y_pred_based_LLM = logreg_resampling.predict(X_test_scaled)\n",
    "print(\"[LLM-based Augmentation Result]\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_based_LLM, y_pred_based_LLM))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test_based_LLM, y_pred_based_LLM))\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_sample_based_SMOTE = concat_original_df.drop(columns=[\"Attack type\"])\n",
    "Y_sample_based_SMOTE = concat_original_df[\"Attack type\"]\n",
    "X_SMOTE, Y_SMOTE = smote.fit_resample(X_sample_based_SMOTE, Y_sample_based_SMOTE)\n",
    "original_data_size = len(X_sample_based_SMOTE)\n",
    "X_augmented = X_SMOTE[original_data_size:]  # 증강된 데이터만 선택\n",
    "Y_augmented = Y_SMOTE[original_data_size:]  # 증강된 라벨만 선택\n",
    "smote_df = pd.DataFrame(X_augmented, columns=X_sample_based_SMOTE.columns)\n",
    "smote_df[\"Attack type\"] = Y_augmented\n",
    "smote_df.to_csv(\"augmented_with_smote_only.csv\", index=False)\n",
    "\n",
    "X_train_based_SMOTE, X_test_based_SMOTE, y_train_based_SMOTE, y_test_based_SMOTE = train_test_split(X_SMOTE, Y_SMOTE, test_size=0.2, random_state=42)\n",
    "scaler_resampling = StandardScaler()\n",
    "X_train_scaled = scaler_resampling.fit_transform(X_train_based_SMOTE)\n",
    "X_test_scaled = scaler_resampling.transform(X_test_based_SMOTE)\n",
    "logreg_resampling = LogisticRegression(max_iter=1000, random_state=42)\n",
    "logreg_resampling.fit(X_train_scaled, y_train_based_SMOTE)\n",
    "y_pred_based_SMOTE = logreg_resampling.predict(X_test_scaled)\n",
    "print(\"[SMOTE-based Augmentation Result]\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_based_SMOTE, y_pred_based_SMOTE))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test_based_SMOTE, y_pred_based_SMOTE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = pd.read_csv(\"WSN-DS.csv\")\n",
    "original_df.columns = original_df.columns.str.strip()\n",
    "augmented_with_LLM_df = pd.read_csv(\"augmented_with_LLM.csv\")\n",
    "augmented_with_LLM_df.columns = augmented_with_LLM_df.columns.str.strip()\n",
    "augmented_with_smote_df = pd.read_csv(\"augmented_with_smote_only.csv\")\n",
    "augmented_with_smote_df.columns = augmented_with_smote_df.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import numpy as np\n",
    "\n",
    "def feature_distribution_comparison(original_data, \n",
    "                                    augmented_data, \n",
    "                                    attack_types:list = ['Grayhole', 'Blackhole', 'TDMA', 'Flooding']):\n",
    "    \"\"\"\n",
    "    이 함수는 원본 데이터와 증강 데이터 간의 K-S Test를 수행하여 \n",
    "    평균, 최대값, 비율 기반의 품질 지표를 반환합니다.\n",
    "    \n",
    "    Parameters:\n",
    "    original_data (DataFrame): 원본 데이터\n",
    "    augmented_data (DataFrame): 증강된 데이터\n",
    "    attack_types (list): 공격 유형 목록 (예: ['Grayhole', 'Blackhole', 'TDMA', 'Flooding'])\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: K-S Test의 각 피처의 D-statistic과 p-value, 평균, 최대값 및 비율 기반 지표\n",
    "    \"\"\"\n",
    "    # 전체 결과를 저장할 리스트\n",
    "    overall_results = []\n",
    "\n",
    "    for attack_type in attack_types:\n",
    "        # 특정 공격 유형에 해당하는 데이터 필터링\n",
    "        original_data_attack_type = original_data[original_data['Attack type'] == attack_type]\n",
    "        augmented_data_attack_type = augmented_data[augmented_data['Attack type'] == attack_type]\n",
    "\n",
    "        # 피처별로 K-S Test 수행\n",
    "        results = []\n",
    "        for col in original_data_attack_type.columns:\n",
    "            if col == 'Attack type':  # 'Attack type' 컬럼은 제외\n",
    "                continue\n",
    "\n",
    "            # K-S Test 수행\n",
    "            try:\n",
    "                statistic, p_value = ks_2samp(original_data_attack_type[col], augmented_data_attack_type[col])\n",
    "            except Exception as e:\n",
    "                print(f\"Error with feature {col}: {e}\")\n",
    "                statistic, p_value = np.nan, np.nan\n",
    "\n",
    "            # 개별 피처의 결과 기록\n",
    "            results.append({\n",
    "                'Attack Type': attack_type,\n",
    "                'Feature': col,\n",
    "                'K-S Statistic (D)': statistic,\n",
    "                'p-value': p_value\n",
    "            })\n",
    "\n",
    "        # 데이터프레임으로 변환\n",
    "        df_results = pd.DataFrame(results)\n",
    "\n",
    "        # 품질 지표 계산\n",
    "        mean_d_statistic = df_results['K-S Statistic (D)'].mean()\n",
    "        max_d_statistic = df_results['K-S Statistic (D)'].max()\n",
    "        d_statistic_above_0_2_ratio = (df_results['K-S Statistic (D)'] >= 0.2).mean()\n",
    "\n",
    "        mean_p_value = df_results['p-value'].mean()\n",
    "        p_value_below_0_05_ratio = (df_results['p-value'] < 0.05).mean()\n",
    "\n",
    "        # 품질 지표를 추가\n",
    "        quality_metrics = {\n",
    "            'Attack Type': attack_type,\n",
    "            'Mean D-statistic': mean_d_statistic,\n",
    "            'Max D-statistic': max_d_statistic,\n",
    "            'D-statistic >= 0.2 Ratio': d_statistic_above_0_2_ratio,\n",
    "            'Mean p-value': mean_p_value,\n",
    "            'p-value < 0.05 Ratio': p_value_below_0_05_ratio\n",
    "        }\n",
    "\n",
    "        # 개별 피처의 결과와 품질 지표를 결합\n",
    "        # overall_results.extend(results)  # 개별 피처의 K-S 결과 추가\n",
    "        overall_results.append(quality_metrics)  # 품질 지표 추가\n",
    "\n",
    "    # 전체 결과를 데이터프레임으로 반환\n",
    "    final_results_df = pd.DataFrame(overall_results)\n",
    "    \n",
    "    return final_results_df\n",
    "\n",
    "# distances = pairwise_distances(original_data, augmented_data, metric='euclidean')\n",
    "# print('평균 쌍별 거리:', distances.mean())\n",
    "\n",
    "# from sklearn.metrics import classification_report\n",
    "# # 모델 학습 및 평가\n",
    "# model.fit(augmented_data, augmented_labels)\n",
    "# predictions = model.predict(test_data)\n",
    "# print(classification_report(test_labels, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attack Type</th>\n",
       "      <th>Mean D-statistic</th>\n",
       "      <th>Max D-statistic</th>\n",
       "      <th>D-statistic &gt;= 0.2 Ratio</th>\n",
       "      <th>Mean p-value</th>\n",
       "      <th>p-value &lt; 0.05 Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Grayhole</td>\n",
       "      <td>0.178079</td>\n",
       "      <td>0.600166</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.444490</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Blackhole</td>\n",
       "      <td>0.119453</td>\n",
       "      <td>0.426772</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.595697</td>\n",
       "      <td>0.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TDMA</td>\n",
       "      <td>0.209310</td>\n",
       "      <td>0.514679</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.242939</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Flooding</td>\n",
       "      <td>0.190569</td>\n",
       "      <td>0.658454</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.389701</td>\n",
       "      <td>0.611111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Attack Type  Mean D-statistic  Max D-statistic  D-statistic >= 0.2 Ratio  \\\n",
       "0    Grayhole          0.178079         0.600166                  0.444444   \n",
       "1   Blackhole          0.119453         0.426772                  0.388889   \n",
       "2        TDMA          0.209310         0.514679                  0.388889   \n",
       "3    Flooding          0.190569         0.658454                  0.444444   \n",
       "\n",
       "   Mean p-value  p-value < 0.05 Ratio  \n",
       "0      0.444490              0.555556  \n",
       "1      0.595697              0.388889  \n",
       "2      0.242939              0.500000  \n",
       "3      0.389701              0.611111  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_distribution_comparison(original_df, augmented_with_LLM_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attack Type</th>\n",
       "      <th>Mean D-statistic</th>\n",
       "      <th>Max D-statistic</th>\n",
       "      <th>D-statistic &gt;= 0.2 Ratio</th>\n",
       "      <th>Mean p-value</th>\n",
       "      <th>p-value &lt; 0.05 Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Grayhole</td>\n",
       "      <td>0.050132</td>\n",
       "      <td>0.249834</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.685321</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Blackhole</td>\n",
       "      <td>0.039884</td>\n",
       "      <td>0.143514</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.660857</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TDMA</td>\n",
       "      <td>0.097885</td>\n",
       "      <td>0.271068</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.290737</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Flooding</td>\n",
       "      <td>0.057257</td>\n",
       "      <td>0.149831</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.497918</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Attack Type  Mean D-statistic  Max D-statistic  D-statistic >= 0.2 Ratio  \\\n",
       "0    Grayhole          0.050132         0.249834                  0.055556   \n",
       "1   Blackhole          0.039884         0.143514                  0.000000   \n",
       "2        TDMA          0.097885         0.271068                  0.055556   \n",
       "3    Flooding          0.057257         0.149831                  0.000000   \n",
       "\n",
       "   Mean p-value  p-value < 0.05 Ratio  \n",
       "0      0.685321              0.222222  \n",
       "1      0.660857              0.166667  \n",
       "2      0.290737              0.444444  \n",
       "3      0.497918              0.166667  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_distribution_comparison(original_df, augmented_with_smote_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
